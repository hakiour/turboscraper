[package]
name = "turboscraper"
version = "0.1.1"
edition = "2021"
description = "A high-performance, concurrent web scraping framework for Rust with built-in support for retries, storage backends, and concurrent request handling"
license = "MIT"
homepage = "https://github.com/hakiour/turboscraper"
repository = "https://github.com/hakiour/turboscraper"
readme = "README.md"
keywords = ["scraping", "crawler", "spider", "web", "async"]
categories = ["web-programming", "asynchronous", "web-programming::http-client"]

[dependencies]
reqwest = { version = "0.12.12", features = ["json", "gzip", "brotli", "deflate"] }
tokio = { version = "1.0", features = ["full"] }
scraper = "0.22"
futures = "0.3"
async-trait = "0.1.83"
thiserror = "2.0"
url = { version = "2.5", features = ["serde"] }
log = "0.4"
env_logger = "0.11"
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
chrono = { version = "0.4", features = ["serde"] }
parking_lot = "0.12"
regex = "1.10"
uuid = { version = "1.6", features = ["v7"] }
erased-serde = "0.4"
anyhow = "1.0"
http-serde = "2.1.1"
mongodb = { version = "3.1.1", optional = true }
rdkafka = { version = "0.37.0", optional = true }
brotli = "7.0"

[features]
default = []
mongodb = ["dep:mongodb"]
kafka = ["dep:rdkafka"]

[dev-dependencies]
wiremock = "0.6"
tokio = { version = "1.0", features = ["full"] }